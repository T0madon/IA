{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6ea3f1",
   "metadata": {},
   "source": [
    "Modelling the nodes of the tree\n",
    "A Decision Tree is formed by nodes: root node, internal nodes and leaf nodes. We can create a Python class that will contain all the information of all the nodes of the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f869d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Contains the information of the node and another nodes of the Decision Tree.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "        self.next = None\n",
    "        self.childs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca0a671",
   "metadata": {},
   "source": [
    "Decision Tree Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    \"\"\"Decision Tree Classifier using ID3 algorithm.\"\"\"\n",
    "\n",
    "    def __init__(self, X, feature_names, labels):\n",
    "        self.X = X  # features or predictors\n",
    "        self.feature_names = feature_names  # name of the features\n",
    "        self.labels = labels  # categories\n",
    "        self.labelCategories = list(set(labels))  # unique categories\n",
    "        # number of instances of each category\n",
    "        self.labelCategoriesCount = [list(labels).count(x) for x in self.labelCategories]\n",
    "        self.node = None  # nodes\n",
    "        # calculate the initial entropy of the system\n",
    "        self.entropy = self._get_entropy([x for x in range(len(self.labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_entropy(self, x_ids):\n",
    "    \"\"\" Calculates the entropy.\n",
    "    Parameters\n",
    "    __________\n",
    "    :param x_ids: list, List containing the instances ID's\n",
    "    __________\n",
    "    :return: entropy: float, Entropy.\n",
    "    \"\"\"\n",
    "    # sorted labels by instance id\n",
    "    labels = [self.labels[i] for i in x_ids]\n",
    "    # count number of instances of each category\n",
    "    label_count = [labels.count(x) for x in self.labelCategories]\n",
    "    # calculate the entropy for each category and sum them\n",
    "    entropy = sum([-count / len(x_ids) * math.log(count / len(x_ids), 2)\n",
    "                   if count else 0\n",
    "                   for count in label_count\n",
    "                  ])\n",
    "        \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0460c3",
   "metadata": {},
   "source": [
    "So we create another private function that computes the information gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df30046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_split_entropy(self, x_ids, feature_id):\n",
    "    \"\"\"\n",
    "    Calculates the weighted entropy after a split by the given feature.\n",
    "    \"\"\"\n",
    "    # store in a list all the values of the chosen feature\n",
    "    x_features = [self.X[x][feature_id] for x in x_ids]\n",
    "    # get unique values\n",
    "    feature_vals = list(set(x_features))\n",
    "    # get frequency of each value\n",
    "    feature_v_count = [x_features.count(x) for x in feature_vals]\n",
    "    # get the feature values ids\n",
    "    feature_v_id = [\n",
    "        [x_ids[i]\n",
    "        for i, x in enumerate(x_features)\n",
    "        if x == y]\n",
    "        for y in feature_vals\n",
    "    ]\n",
    "\n",
    "    # compute the entropy after the split\n",
    "    split_entropy = sum([v_counts / len(x_ids) * self._get_entropy(v_ids)\n",
    "                         for v_counts, v_ids in zip(feature_v_count, feature_v_id)])\n",
    "\n",
    "    return split_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf628d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_feature_min_entropy(self, x_ids, feature_ids):\n",
    "    \"\"\"Finds the feature that minimizes the entropy after split.\"\"\"\n",
    "    features_entropy = [self._get_split_entropy(x_ids, feature_id) for feature_id in feature_ids]\n",
    "    min_id = feature_ids[features_entropy.index(min(features_entropy))]\n",
    "    return self.feature_names[min_id], min_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(self):\n",
    "    \"\"\"Initializes ID3 algorithm to build a Decision Tree Classifier.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # assign an unique number to each instance\n",
    "    x_ids = [x for x in range(len(self.X))]\n",
    "    # assign an unique number to each featuer\n",
    "    feature_ids = [x for x in range(len(self.feature_names))]\n",
    "    # define node variable - instance of the class Node\n",
    "    self.node = self._id3_recv(x_ids, feature_ids, self.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _id3_recv(self, x_ids, feature_ids, node):\n",
    "    \"\"\"ID3 algorithm. It is called recursively until some criteria is met.\n",
    "    Parameters\n",
    "    __________\n",
    "    :param x_ids: list, list containing the samples ID's\n",
    "    :param feature_ids: list, List containing the feature ID's\n",
    "    :param node: object, An instance of the class Nodes\n",
    "    __________\n",
    "    :returns: An instance of the class Node containing all the information of the nodes in the Decision Tree\n",
    "    \"\"\"\n",
    "    if not node:\n",
    "        node = Node()  # initialize nodes\n",
    "    # sorted labels by instance id\n",
    "    labels_in_features = [self.labels[x] for x in x_ids]\n",
    "    # if all the example have the same class (pure node), return node\n",
    "    if len(set(labels_in_features)) == 1:\n",
    "        node.value = self.labels[x_ids[0]]\n",
    "        return node\n",
    "    # if there are not more feature to compute, return node with the most probable class\n",
    "    if len(feature_ids) == 0:\n",
    "        node.value = max(set(labels_in_features), key=labels_in_features.count)  # compute mode\n",
    "        return node\n",
    "    # else...\n",
    "    # choose the feature that maximizes the information gain\n",
    "    best_feature_name, best_feature_id = self._get_feature_min_entropy(x_ids, feature_ids)\n",
    "    node.value = best_feature_name\n",
    "    node.childs = []\n",
    "    # value of the chosen feature for each instance\n",
    "    feature_values = list(set([self.X[x][best_feature_id] for x in x_ids]))\n",
    "    # loop through all the values\n",
    "    for value in feature_values:\n",
    "        child = Node()\n",
    "        child.value = value  # add a branch from the node to each feature value in our feature\n",
    "        node.childs.append(child)  # append new child node to current node\n",
    "        child_x_ids = [x for x in x_ids if self.X[x][best_feature_id] == value]\n",
    "        if not child_x_ids:\n",
    "            child.next = max(set(labels_in_features), key=labels_in_features.count)\n",
    "            print('')\n",
    "        else:\n",
    "            if feature_ids and best_feature_id in feature_ids:\n",
    "                to_remove = feature_ids.index(best_feature_id)\n",
    "                feature_ids.pop(to_remove)\n",
    "            # recursively call the algorithm\n",
    "            child.next = self._id3_recv(child_x_ids, feature_ids, child.next)\n",
    "    return node"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
